{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "910557f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "199384c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 172 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../data/cross_circles/scaled/s64_1/train/',  # this is the target directory\n",
    "        target_size=(64, 64),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',color_mode='grayscale')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '../data/cross_circles/scaled/s64_1/test/',\n",
    "        target_size=(64,64),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',color_mode='grayscale')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb4ea6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b63c32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#model.add(Lambda(standardize,input_shape=(28,28,1)))    \n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=(64,64,1)))\n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())    \n",
    "model.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
    "    \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a52089bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172/172 [==============================] - 12s 63ms/step - loss: 0.6934 - accuracy: 0.5041 - val_loss: 0.7551 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      " 92/172 [===============>..............] - ETA: 4s - loss: 0.6933 - accuracy: 0.5148"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-72d1436a65f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         validation_steps=80 // batch_size)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'first_try.h5'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# always save your weights after training or during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=172 // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=80 // batch_size)\n",
    "model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713fdef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bacc216e",
   "metadata": {},
   "source": [
    "## Circle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e94c55bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "  \n",
    "# Read image.\n",
    "img = cv2.imread('../data/cross_circles/scaled/s256/circles/b_c_1.jpg', cv2.IMREAD_COLOR)\n",
    "  \n",
    "# Convert to grayscale.\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "# Blur using 3 * 3 kernel.\n",
    "gray_blurred = cv2.blur(gray, (3, 3))\n",
    "  \n",
    "# Apply Hough transform on the blurred image.\n",
    "detected_circles = cv2.HoughCircles(gray_blurred, \n",
    "                   cv2.HOUGH_GRADIENT, 1, 20, param1 = 50,\n",
    "               param2 = 30, minRadius = 1, maxRadius = 40)\n",
    "  \n",
    "# Draw circles that are detected.\n",
    "if detected_circles is not None:\n",
    "  \n",
    "    # Convert the circle parameters a, b and r to integers.\n",
    "    detected_circles = np.uint16(np.around(detected_circles))\n",
    "  \n",
    "    for pt in detected_circles[0, :]:\n",
    "        a, b, r = pt[0], pt[1], pt[2]\n",
    "  \n",
    "        # Draw the circumference of the circle.\n",
    "        cv2.circle(img, (a, b), r, (0, 255, 0), 2)\n",
    "  \n",
    "        # Draw a small circle (of radius 1) to show the center.\n",
    "        cv2.circle(img, (a, b), 1, (0, 0, 255), 3)\n",
    "        cv2.imshow(\"Detected Circle\", img)\n",
    "        cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227a398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96d7be53",
   "metadata": {},
   "source": [
    "### Closed Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e32e2f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../data/cross_circles/scaled/s64/circles/b_c_1.jpg')\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5cd036b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchy  = cv2.findContours(img_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da6d1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_contours = []\n",
    "open_contours = []\n",
    "for i in contours:\n",
    "    if cv2.contourArea(i) > cv2.arcLength(i, True):\n",
    "        closed_contours.append(i)\n",
    "    else:\n",
    "        open_contours.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c6fe830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 0,  0]],\n",
       " \n",
       "        [[ 0, 63]],\n",
       " \n",
       "        [[63, 63]],\n",
       " \n",
       "        [[63,  0]]], dtype=int32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ce4bef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed_contours[0][1][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9dda820d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [141, 141, 141],\n",
       "        [142, 142, 142],\n",
       "        [144, 144, 144]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [144, 144, 144],\n",
       "        [142, 142, 142],\n",
       "        [143, 143, 143]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [142, 142, 142],\n",
       "        [143, 143, 143],\n",
       "        [144, 144, 144]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [144, 144, 144]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [142, 142, 142],\n",
       "        [144, 144, 144]]], dtype=uint8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.circle(img, (closed_contours[0][0][0][0],closed_contours[0][0][0][1]), radius=2, color=(0, 0, 255), thickness=5)\n",
    "cv2.circle(img, (63,63), radius=5, color=(0, 0, 255), thickness=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a109f806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f52bc24b860>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjPElEQVR4nO2da6wd13Xf/8uU+NKDFB/i61ImZdIRZLiWA8KxYaNQpDpQ0yD+YhhxgkIoVPCL48qPwpZaoHCKFrA/6NU4MEDUbvTBjew8XAlCkERlJKQFCtlULTt6hBLF8im+JL5NSpTk1Q9nzmjNytnr7tl3zjmXmv8PILjP2TN77zMz+85ae629lqgqCCHvfd437QEQQiYDJzshPYGTnZCewMlOSE/gZCekJ3CyE9IT5jTZReQOEdktIntE5J6uBkUI6R4ptbOLyAIALwH4NIBDAH4C4POq+kJ3wyOEdMUVczj3YwD2qOpeABCRRwB8BkBysousUmDTHLpsMjNzzLUvWed14UiU29d8IfrN0/wtXd8L317qt7XpN2o/55y59J3LsL+TJ0/i/PnzIzufy2TfAOCg+XwIwK/Fp2wCsGsOXTb56lcfbHy2F9hfbHuBcy/2L3/5y2TdlVdemdVe6UMVYdv056QezOi3+Dbe9753tTt73oIFC5Jt5Lbvr8c777yTHIdt047Jc8UV7z7Gb7/9dqMuNWbbrx9X7jX1Y8zpd9Q5Ud+5xw2vz3333Zc8f+wLdCKyXUR2icgu4MS4uyOEJJjLm/0wgI3m80z1XQNV3QFgBwCIbJuz/PLggw+Ztv9RXyPLQPrNUCre2r/OUV++X/9GKek7V0qxfbeRdFJvW//WtOf53xm9iS3R70xJT23eyqnfEkkznuhep8bv397Rfbd9RxJBJKkN68LnIVkzOz8BsFVENovIQgC/A+CxObRHCBkjxW92VX1bRH4fwF8DWADge6r6fGcjI4R0ylzEeKjqXwL4y47GQggZI3Oa7NPA6kjRCnCkR5eYUjy278WLFzfqrH7mx5ha6R71eYjX42wb4zAj5urbkR598eLFunzp0qWR5/i+rI4ONK9rpNf6tYSc9t96663GcdEzEa1v5OrsdszRPct9plMWg2gNhO6yhPQETnZCesJlIcY/8MCDdVk1EFOMyOZFOyselXqMpUxNkTju62zfXlzOFcmtCBqJ+LmiaTR+K4KfO3eucdypU6eSdW+++ebIvqJrv2TJksbnVatW1eUVK1bU5aVLlzaOs+17VSClauQ6x5Tif6e9T22el9z2c55pvtkJ6Qmc7IT0BE52QnrCvNTZrY7uyXVvjfThyM0z6ivVvtVrgaZ+1kYvT5nUvFkrMuOk9FJ/nNWpz54926g7f/58XT59+nRdthtOAGDhwoV1edmyZY06azazx0WbXay5Dhjs4Bo1jpmZmcZxy5cvT7Zv125y3YdLXWmjcyJ32ZQbbzRGT856D9/shPQETnZCesLUxPj77ru/8dmKiJF5zRKZk3LFeE/knZYS9bx4W9q+FfXscVYMBpqiqTcxpkRwL6qnxFug+Xuuv/76unz11Vc3jrOf/TVIqTzRri7v1WZF5P3799flvXv3No5bt25dXV6/fn2jzo7Ljil39yEQm1lTtFETovNyGY5rXLveCCGXEZzshPSEiYrxMzPH8OUvD8T3NuJKSjyPRCUvmpZsoMkNXhGtMLcJbGE/WzHTi7dnzpypy1ZU93W276uuuqpx3Jo1a+rytdde26iznmzR6nAJXny218qrK9bKsWnTprr82muvNY47ceLdCEjeMrJx47vxVZqqYtrS0kVIM09kQUl5M7YZ4/DZ4UYYQggnOyF9gZOdkJ4wcdNbapN95DE26vzZyNV3ouASUZuRbmW9x3yd1yktVqe0u8iOHj3aOO7YsXfj5Xs91+4OW7t2bV2+5pprkv1G6wo5QQ6B/PDL/jj7m3N3CNrdcACwaNGiunzgwIFG3Z49e+ryjTfeOLJf336bNZhc77dcU1+uJ1/J+gnf7IT0BE52QnrCxMX4oUjkgwyUmrIsJRsWIo+u6NgoW8kbb7xRl72YHYlfNhjE7t276/KFCxeS51iPOaApxltzmx+j9aCLPAAjs5O9HqXx2lNeg/7Y6Dj7m/1z9fLLL9dlqw5t2LChcZy9HlEADP+8pOLql6Z/yhXVc2PhNdqe9QhCyHsCTnZCegInOyE9YeI6+1DnaRPwz+pJUeC+kqAUuTvb/OfIfGf19Ei3ev311xt1dmeXdYON3Gq9q6vfmZYiN6dYVxlqU0RBMa3ubK+xX2OI9O0tW7bU5X379tVla64Dmrvl/E5CO8YoUEn0bI47LXYnwStE5HsiclxEnjPfrRCRJ0Tk5er/6+Y4VkLImMkR4/8YwB3uu3sA7FTVrQB2Vp8JIfOYWcV4Vf07Ednkvv4MgFur8sMAngLw9bkMJNoVlBs8IFdUyk1vFBGZk+wuNV9nxfNnnnkmeZ4Vz20ACaBpNvKx1r0YOySKVR55d6WCP4z6nKqLrlUUUMKK0/b58MfZ++nFc6vWWJOo3zlnr7dP55US1f34I3JTjuXuuiyh9Klfo6pHqvJRAGuigwkh02fOrzgd/ClK/qkSke0isktEdv3iF7+Ya3eEkEJKV+OPicg6VT0iIusAHE8dqKo7AOwAgI0bN2pKhIlis6W8lNoEqMgVK3MDW0Qr1lYMPHjwYKPuhRdeqMt+Vdlu8Ni8eXNdvu665vqnHbMXK1OphCLVxde18Soc0sWqfbTKbi0cNgy2r/MivvU+tBuDfLqqV199tS7baw80x+89Im1/KbXDt+EZd3y6IaVv9scA3FmV7wTw6JxGQQgZOzmmtz8B8H8A/IqIHBKRuwB8E8CnReRlAP+s+kwImcfkrMZ/PlF1e8djIYSMkYl60IlIrR9Gnmu5AQKiuOtdpGX25LZpTTw+8IQd4+rVqxt1H/7wh0e253VZ20a0NhF5dFly1z66CMRYslsLaP7mNtcjlabLmzNfeeWVuuzXBHJzCUS6d+71KTHl5ULfeEJ6Aic7IT1homK8qtbiTORJ5cXKlCjZxUaM0rhqkfnOesn5wBMf+MAH6vINN9zQqLPiaeQ1WBID3x9n+/JmIr8RZFS/vv3I6zF1jifagGLH78drxfjIw816KHrPw6VLl9Zlb5azQUB8DH/7OyNvw4jSuIpt4ZudkJ7AyU5IT+BkJ6QnTDx4xVC/Su3OAmIX1hKX2HFg9aeLFy826l566aW6bHVBoJmzLEqVnBs7P3cHXxQn3V/HSAdOjaPUpBa5/ub2FWF17Oj6rly5si77oCK2rnTXW+45XeRFSME3OyE9gZOdkJ4wtfRPXgyJdgxZESVKFxR50KXEnDaeTqmADzZ2nK/70Ic+1Kiz6kuUGsrWRR5jubH2PFEaqlTst1KvsMgEmBuYxJIb5x5o7lKzIr1/xmyQC79T0W7NXr58eaPO3ovc+PKeVKz4NuoKxXhCSA0nOyE9YeIbYVKr8JF4az97DybffoqUiBWtekeBIU6ePFmX/ertTTfdVJd9PLPc1D/RGKN4fbmicLS5I0UbsTKVsitqI7re0Tii35JSefyzYsV96zEHxGK8bdOqoqXXKiKyNnUSSpoQ8t6Ak52QnsDJTkhPmFrK5i483KK0SF4PsmsC1uwU6W4+Gq5t/9ChQ3V53bp1jeOiVMmWLoJBjMPEmCJaS5nt2NQ4Svou3f2Vm/bLB/g8fPhwXbZBK4F0Wiq/g6+LXAVzZfojIIRMBE52QnrC1DzooqARHisCRWaWKE56yhTkj7Pil/fUsp5Vtg0vxtvNL20yzaY8zcYtgkd1ufH8o/6ijTslZr8uNt1E7S9btqxRZzc2+fh0Vj3sOn4cPegIIUVwshPSEzjZCekJE9fZh0T6dqlOY9vwObmsuc3q4tHuOxv/HQBOnDhRl20+MB+gwuql3tW1JM1xtK6Qa9LpIo55FCwkN0hom3Gk6nLzCoz6PGp8Hu+2a9M5+2CUNj9fFNu+5Pn25K45pMhJ/7RRRJ4UkRdE5HkRubv6foWIPCEiL1f/XzdbW4SQ6ZHzWngbwFdV9WYAHwfwBRG5GcA9AHaq6lYAO6vPhJB5Sk6utyMAjlTlcyLyIoANAD4D4NbqsIcBPAXg67O0VYs6XiSJ4o9ZESXapVZiJop2UO3bt69RZ00yNn1QrulqNkpirXtyPehy49JP0uTVBaXpu2ydf8bsvT516lSjzorxlsjEWGKynI2cnXOtFuhEZBOAjwJ4GsCa6g8BABwFsKZNW4SQyZI92UXkagB/DuBLqnrW1ungz9HIP6kisl1EdonILu9rTgiZHFmTXUSuxGCif19V/6L6+piIrKvq1wE4PupcVd2hqttUdZsPCkAImRyz6uwyUBy+C+BFVb3fVD0G4E4A36z+fzSnwxIdLTcefEnuMd/e2bPvCi3nz59v1PngkUOiIIq5brv+c+4ury5STI9Dh+xi/cFS8gyU9u3bty+pAwcONOps5KRFixbV5WhtqZS55jnMsbN/EsC/BPD3IvJs9d2/w2CS/1BE7gKwH8DnWvdOCJkYOavx/xtA6k/p7d0OhxAyLiYecHJoYvNiTuRhlJvKOHenWGRmOXLkSF1evXp1o856ykUx6nNFyVyTV9RGRO4Ou9y+2ojPuabOklRIbdSJ3PFHOyZTcfT95+i5iu5t6l7kpgzPhb7xhPQETnZCesLUNsJ4Ualk80vkFZa7AcVnYD1z5kxd/uAHP9ios15+uQEZ2sRtS403ymrbBaVifPQ7U7HtI8uFJ3UNcsXxqL1oE5XfxGI/+zpLqcqTq1LNNfsr3+yE9AROdkJ6Aic7IT1hojq7qtY6SaSH5pqyIj3F76JL6VM2JjjQTN0b5fWKTG8RUZ62uXoXekp2C/o2c4M8+Pbt59Rahx9jLlEQz9zAFn681rzmY77bz0uWLGnU2QAntq7Nrrfc653rfZmCb3ZCegInOyE9YeIedEPxpo0Ybyk1E6XEI296W79+fV0uTdnTdUAGTzSuXJWnC3NPNKYSE2MXnny55HpYztZfSk3oYsNPF2qehW92QnoCJzshPYGTnZCeMG/ixpfQRrey/dnwWF5n9zvdcvvOJVf3nKtrpO9rHDpk7pjGHbSyNC69xZriSk2RpYxjDWIUfLMT0hM42QnpCRMX41MedF0EMYjixts6G/vbek4BzThiNr5Y1HcXIn1EaXCMXNrci9x+SwJs5JoHx3G9c1UN73kXeUSm2uhCJSm5z3yzE9ITONkJ6QkTF+NTHnQlYl8UgCDVL9AMF21T+wDNTQ+5XlZtsop2sULeRcbbiNTqcyTue/HW9mdF3VJPu669EqPfEt1P/4z5bMFDSmP+RWOM4EYYQkgNJzshPYGTnZCeMDXTW0SpaSXSraxOactr165tHBcFHizRlT1dm808Kd1zHF5aJTvionWWLu67p2SdxdfZ58XXRQEoc+n6PqWY9c0uIotF5Mci8jMReV5E/qD6frOIPC0ie0TkByIyeqWCEDIvyBHj3wRwm6p+BMAtAO4QkY8D+BaAB1R1C4BTAO4a2ygJIXMmJ9ebAhimM72y+qcAbgPwu9X3DwP4BoDvzNJWLbblxguPaGO+u3DhQl22XnM+jXQUq60Lz7KILjKfjtvTLLevknvY9eaf6Lw2wSsuXbqUrOsieEVqjG28EjvbCCMiC2SQwfU4gCcAvALgtKoOjdKHAGzIaYsQMh2yJruqvqOqtwCYAfAxADfldiAi20Vkl4jssltLCSGTpZXpTVVPA3gSwCcALBeRoRowA+Bw4pwdqrpNVbd5kZkQMjlm1dlFZDWAt1T1tIgsAfBpDBbnngTwWQCPALgTwKMZbdW6xbhNV759G6TCujhGu+OilMpdBBeMgiSUBnxIXYPS4JmWKE9bFzp1ro7axgU51UZ0PXyddaH2+QhS17g0tr0lasPjxzWKHCPhOgAPi8gCDCSBH6rq4yLyAoBHROQ/AfgpgO9mtEUImRI5q/E/B/DREd/vxUB/J4RcBkzcg24obpSapErEbKC5023FihXJ41K7tXx/9rhoh1PuTjx/Xm77nlxTUyQ+R2mGUuMoiWXvxxGZPe298OmZcu9Z1Ff0XNkUT1E656iNyIuwRNUogb7xhPQETnZCesLUNsK08Q5KiWLROVFWUetB58XbKDtrSlz0YmVK7fDkis9tAiHkrsBHonpJfL1IXcn16vMiuL0Xtv0oQ2/0W6Kss9H1sPfXm4/teaWbenKtMHOFb3ZCegInOyE9gZOdkJ4wtfRPnlyvsNw2vL5qY8Bbnb2NzpsyqeV6wnn8eSnTTbS+UapvRzp2F7uwcsm9PrmBLyOPyNQ5/nNkervuuusadal74U10ufHxozFOZNcbIeTyh5OdkJ4wNTF+HDHRorqU6a10XLkiW5usn7lms8g8mBpH1FdE7vi72Njk+0pt7mjzu+x1tKpcrgoFNLP+Wu9LT+5GmFzaqGgU4wkhNZzshPQETnZCesJlkbJ51Pmz4XUm+zlyl025PwJpN1jvellivouIdnJFROaqXFfaiJIAkeMw1+Xu4IuuR667bGR+jJ6JXMaRB24I3+yE9AROdkJ6wmWR/il1ThciYZsAGLmxwnLJFfHbeLvlevlFpLy9SmO/laSJAtKidRRvLTJ5RTHzohRP9rxFixZl9d1GzJ5UrH++2QnpCZzshPSEebMRputN+9HmlMgDzYqIuWJrmxX3khXsNqqGpTQuXElfpWGgo7qSoCVRG1FQER+AxGL7W7x4cbK/XFWjjTWh5LgUfLMT0hM42QnpCZzshPSEeaOzd03k/dbmvBS5umekz3svq5QelpPaZ1TfXeyIy03L3IW5NDeQhdevbd9+B2JuX1HwCrtbLrf92fpLMS9Mb1Xa5p+KyOPV580i8rSI7BGRH4jIwtnaIIRMjzZi/N0AXjSfvwXgAVXdAuAUgLu6HBghpFuyZBIRmQHwLwD8ZwBfkYGscRuA360OeRjANwB8J6MtAO08rlKpc3wbVty1opfHis9ezLamlUuXLjXqrAgXtRF5Y5VkYG0jclqilEPR+O1GIXsdow0/kQmzNP2TbSPyTovUnNwNOdGzk/vM2fFH6aWisZQ8H7O1Xx8z6xEDHgTwNQDDK74SwGlVHSpPhwBsyGyLEDIFZp3sIvJbAI6r6jMlHYjIdhHZJSK7zp8/X9IEIaQDcsT4TwL4bRH5TQCLAVwL4CEAy0XkiurtPgPg8KiTVXUHgB0AcMMNN3Sbz4YQkk1OfvZ7AdwLACJyK4B/q6q/JyJ/CuCzAB4BcCeAR9t0XOI2OhuRXmf1UGu68e6PUVDCVECCNu6skf6aa2LL1YFLU/6mXEzbuGh24f6c0lG7cAOOzvNrNUuWLKnLCxc2jU6p9ZnSXG+5azWece96+zoGi3V7MNDhvzuHtgghY6aVh4CqPgXgqaq8F8DHuh8SIWQczMu48blBI9qkVlq6dGldfvPNN+vysmXLGsdZET93jG289UpiueemQ47Oi0w1Uby+XFWg6/TCvs1ox1oUPy5F1MaZM2cadVbVi86LVJ6S+95GBcyBvvGE9AROdkJ6wrwJJR2Ji7liTtTGNddcU5fPnj1bl6+//vpkG3713a7oR6GCczeP5Ip6pZlaoyAdUTy2XHGxZMW9TbCNlPrSJhZeSrSOLCj2+QCamVsjz8yu0z+1gemfCCE1nOyE9AROdkJ6wkR1dlWdc+raEn0SaOrsR44cqcu5ujeQH9Qht40oOGLqHE8UHCOX3HWFNuakEnKvY2kq6ihwiP3sPehsmuYu1ia6uG5M/0QIScLJTkhPmKgYLyK1+FEq5uTWeZHYetBZ3njjjcZnm94nN3tqG9NVyQagXHEfKN+4kkM09tLY9rn9lcbiT4n/Ppbc66+/nqyzG2EitakkAEspbTbJ1GOYc6+EkMsCTnZCegInOyE9YeLuskPdJdJDo11kpfqfxZpSTp482ahbv379yH6BOEijpet47RG5pr3SdZBccu9LF66uXZgzventtddeq8urVq0Kx5yi6+M8cw0Iwjc7IT2Bk52QnjA1Md5TEletjUeX3a20cuXKurx3797GcRs3bqzLXtTLDerQxkSVc16k1pR6tZXuzMulxPTmf2cq1VKJ2clz7ty55Oebb745u3075ihWfqk5Npdxx6AjhFxGcLIT0hMmLsbneKGVisGWSNSLvOSsJ9Xy5cuTbeR6S0WZWr2YmrJI+DFalcTXpSwXpeJ4KgVTG3L79tcj5TXnf7M9zgeXSF2P/fv3N46zVhgbpMTjM8imAlZEgThyxfbS0N0p+GYnpCdwshPSEzjZCekJU4sbH9GFKcLrf6nUwD7g5KuvvlqXracdkB8jPDeOeRSUMFrDGEf6o1Qbub+lC68wrw/bNq0ebeP+A00d3t93e69tPHi/lmKfg8gLL2UOBOLgGCWpuLqYB5bc/Oz7AJwD8A6At1V1m4isAPADAJsA7APwOVU91enoCCGd0ebPza+r6i2quq36fA+Anaq6FcDO6jMhZJ4yFzH+MwBurcoPY5AD7uuznZSKGz/qmC5JiWI2JjgAHDt2rC6fOHGiUWdFvWhTTK53WkRkNisR47uIXx9Rak5Kier+2IsXLyaPs2K8VwWsyG/NbWvWrGkcd+2119blKC6h/52pLK5RRt5I7cvNADzOjTAK4G9E5BkR2V59t0ZVh5EbjwJYM/pUQsh8IPfN/ilVPSwi1wN4QkT+wVaqqorIyD811R+H7cA/fosSQiZH1ptdVQ9X/x8H8CMMUjUfE5F1AFD9fzxx7g5V3aaq266++upuRk0Iac2sb3YRuQrA+1T1XFX+DQD/EcBjAO4E8M3q/0fbdNzFbqqIyE3V6lNe/92wYUNdPnDgQKPOBjXIXXNoE3gwN9dbrs7eRdDHLsjVNb2rqx2zDfro27Bx3n3d4cOH6/LChQvr8szMTLLvNu7PllSKaaAsrXSk25eQI8avAfCj6gJcAeC/q+pfichPAPxQRO4CsB/A5+Y0EkLIWJl1sqvqXgAfGfH96wBuH8egCCHdM3EPupQ42bW5x4tR9lgrsvnjli1bVpet2Ac0zXJ2l1Sb9Ly5XmiRaSw39vxcTTVtyP3N0XHeXGVFZhvf398X+5u9udQGpdiyZUtd9p5wFy5cqMs+x0Akgtt2Ul6avi43ZVeb54px4wkhNZzshPQETnZCesK80dm7OD+37Sj6itWLrBkOaLpb2hTQ3n/A6nFdBIRsU9d1FJSug09G4/CurlY3t3X+OBvz3ZragKaLc+QS69cBUvh1BTuWyEU2lyh/giW1My+6R3yzE9ITONkJ6QlTC17RRiTswvurJACBFdWBprh+9OjRuvz+97+/cZzdlRWlkIp2NUUBCse9Y7BrL7zI9GZ/pw0ECjTNZnbX25EjRxrHWbOc3822adOmuhyZxuwzEZnNPKnfFnnQRW1EHnqlcenrMc16BCHkPQEnOyE9QcbtWdXoTLYpsGvW4/7wD79d1H7uCrYVqXwgBLu6GgUqeP755+vy5s2bG8dZcT+KhR55UkXBMaLNNJbStEvRGHNJXe8opZYXz23MOLvZxW+VTq24A83rbwNZRJtdIrXJj98+P9HvjK6jPTZS8+xv+eIXfz/R2jao7hp54/lmJ6QncLIT0hM42QnpCfNSZ/c89NB/SbSXju/tvZlKcm35NqzeaPXJgwcPNo7bunVrXfY6pG0j8rjKzW0W7YiLjrM6ZLR2EOnvqWCLfhyRXm5z69lrAzR181y9PDcWf3RclD8vNxhlFDzFP3+p3H1f+tLdyb7SUGcnpPdwshPSEy4LMT6FN9HlivGRGST3uFQ8cqAppq1du7ZRZ9NARzHX7PgjkTDy9rJmoTYxyFPPhN+AEm0oskEkbNAPP97Vq1ePLPvxR78lUidS6or/LZY2KcNtm9E9s/355+ruu/9Nsr/2UIwnpPdwshPSEzjZCekJl7XO7rE6fKTXRWan3F1HFp9C2JqX7G4tAFi5cmVd9oEN7VhsMIUoRbHX+1O6uNdRI5fh1K49/1us+dGa0IDm9U+Z0Hydbz91n6L1B0/K5NVm11iuqTPXtFdmUsuFOjshvYeTnZCeMLXgFeMg8lIqCQwRBVqwdV4MtqmFTp061aiz3nZeBLfBG2xfPj7a+fPn67JXLVLmsMhEF3ny2fO8aGrVEKueAE0zmv1d/npbr7loh2CuqTC3LgpgUpreOjIBdhGfbq5kvdlFZLmI/JmI/IOIvCginxCRFSLyhIi8XP3PFK2EzGNyxfiHAPyVqt6EQSqoFwHcA2Cnqm4FsLP6TAiZp8y6Gi8iywA8C+BGNQeLyG4At6rqkSpl81Oq+itxW+Ndjbd477ou4qrlBpewIpuNj+bxYrwVz1NqB9AU633fVjy144hEU9++XbmP1InFixe3HmMXobXbpP2yRBtVohRPuWpONMZuveQi5rYavxnACQD/TUR+KiL/tUrdvEZVhzamoxhkeyWEzFNyJvsVAH4VwHdU9aMAfgEnsldv/JF/okVku4jsEpFdg78ZhJBpkDPZDwE4pKpPV5//DIPJf6wS31H9f3zUyaq6Q1W3qeo2YPWoQwghEyDLg05E/heAf62qu0XkGwCuqqpeV9Vvisg9AFao6tfidians3u+/e0/MuNI66sRuemmIxOP1dMjPdcSmaS83m/J1ZVzTU25ASqivqNdaZ7ctZUS01u0K9L/lmgcKdPkV77y5eR4x0taZ8+1s38RwPdFZCGAvQD+FQZSwQ9F5C4A+wF8rouhEkLGQ9ZkV9VnAWwbUXV7p6MhhIyN95QHXUTXaZGiuGRW1Is2sXjPOyuS58aGj8TiSMyOgnSk+vbH5YrWJTHcPLnqVm48eN9ebjzASW4ca8ODDz4EALjvvpFLZwDoG09Ib+BkJ6QncLIT0hN6o7Nbol1vka6cco30pjF7XGQ2iwI4ptrzbUZ6dKTn2jYic1KqbSA/RbGti3TlXH2+1MU5uvZRmu3c56WL1OK53H//A+6b2d/bfLMT0hM42QnpCROOQScnMHDAWQXgtYl1PJr5MAaA4/BwHE3ajuP9qjrSL32ik73uVGTXwFd+esyHMXAcHMckx0ExnpCewMlOSE+Y1mTfMaV+LfNhDADH4eE4mnQ2jqno7ISQyUMxnpCeMNHJLiJ3iMhuEdlTBbyYVL/fE5HjIvKc+W7iobBFZKOIPCkiL4jI8yJy9zTGIiKLReTHIvKzahx/UH2/WUSeru7PD6r4BWNHRBZU8Q0fn9Y4RGSfiPy9iDw7CKE2tWdkbGHbJzbZRWQBgD8C8M8B3Azg8yJy84S6/2MAd7jvphEK+20AX1XVmwF8HMAXqmsw6bG8CeA2Vf0IgFsA3CEiHwfwLQAPqOoWAKcA3DXmcQy5G4Pw5EOmNY5fV9VbjKlrGs/I+MK2q+pE/gH4BIC/Np/vBXDvBPvfBOA583k3gHVVeR2A3ZMaixnDowA+Pc2xAFgK4P8C+DUMnDeuGHW/xtj/TPUA3wbgcQAypXHsA7DKfTfR+wJgGYD/h2otretxTFKM3wDgoPl8qPpuWkw1FLaIbALwUQBPT2Mslej8LAaBQp8A8AqA06o63CEyqfvzIICvARjuNlk5pXEogL8RkWdEZHv13aTvy1jDtnOBDnEo7HEgIlcD+HMAX1LVs9MYi6q+o6q3YPBm/RiAm8bdp0dEfgvAcVV9ZtJ9j+BTqvqrGKiZXxCRf2orJ3Rf5hS2fTYmOdkPA9hoPs9U302LrFDYXSMiV2Iw0b+vqn8xzbEAgKqeBvAkBuLychEZ7n2dxP35JIDfFpF9AB7BQJR/aArjgKoerv4/DuBHGPwBnPR9mVPY9tmY5GT/CYCt1UrrQgC/A+CxCfbveQzAnVX5Tgz057Eigw3P3wXwoqreP62xiMhqEVlelZdgsG7wIgaT/rOTGoeq3quqM6q6CYPn4W9V9fcmPQ4RuUpErhmWAfwGgOcw4fuiqkcBHBSRYRq12wG80Nk4xr3w4RYafhPASxjoh/9+gv3+CYAjAN7C4K/nXRjohjsBvAzgf2IQ937c4/gUBiLYzzHIn/dsdU0mOhYA/wTAT6txPAfgP1Tf3wjgxwD2APhTAIsmeI9uBfD4NMZR9fez6t/zw2dzSs/ILRgkV/g5gP8B4LquxkEPOkJ6AhfoCOkJnOyE9AROdkJ6Aic7IT2Bk52QnsDJTkhP4GQnpCdwshPSE/4/rCFMsbq1Q+EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da0884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
